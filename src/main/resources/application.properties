
##端口
server.port=8080
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.url=jdbc:mysql://localhost:3306/tv?useUnicode=true&serverTimezone=Asia/Shanghai&characterEncoding=utf8&autoReconnect=true&useSSL=false&allowMultiQueries=true

##连接池
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.druid.username=root
spring.datasource.druid.password=liruia
spring.datasource.druid.max-active=15
spring.datasource.druid.max-wait=3000
spring.datasource.druid.initial-size=10
spring.datasource.druid.min-idle=5

#redis
spring.redis.host=127.0.0.1
#Redis服务器连接端口
spring.redis.port=6379
#Redis服务器连接密码（默认为空）
spring.redis.password=
#连接池最大连接数（使用负值表示没有限制）
spring.redis.pool.max-active=8
#连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.pool.max-wait=-1
#连接池中的最大空闲连接
spring.redis.pool.max-idle=8
#连接池中的最小空闲连接
spring.redis.pool.min-idle=0
#连接超时时间（毫秒）
spring.redis.timeout=30000
##thymeleaf
spring.thymeleaf.cache=false
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.mode=HTML5
spring.thymeleaf.enabled=true
#
###kafka
#
############【Kafka集群】###########
#spring.kafka.bootstrap-servers=127.0.0.1:9092
############【初始化生产者配置】###########
## 重试次数
#spring.kafka.producer.retries=0
## 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
#spring.kafka.producer.acks=1
## 批量大小
#spring.kafka.producer.batch-size=16384
## 提交延时
#spring.kafka.producer.properties.linger.ms=0
## 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
## linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
#?
## 生产端缓冲区大小
#spring.kafka.producer.buffer-memory =16777216
###33554432
###16777216
## Kafka提供的序列化和反序列化类
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
## 自定义分区器
## spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner
#
############【初始化消费者配置】###########
## 默认的消费组ID
#spring.kafka.consumer.properties.group.id=defaultConsumerGroup
## 是否自动提交offset
#spring.kafka.consumer.enable-auto-commit=true
## 提交offset延时(接收到消息后多久提交offset)
#spring.kafka.consumer.auto.commit.interval.ms=1000
## 当kafka中没有初始offset或offset超出范围时将自动重置offset
## earliest:重置为分区中最小的offset;
## latest:重置为分区中最新的offset(消费分区中新产生的数据);
## none:只要有一个分区不存在已提交的offset,就抛出异常;
#spring.kafka.consumer.auto-offset-reset=latest
## 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
#spring.kafka.consumer.properties.session.timeout.ms=120000
## 消费请求超时时间
#spring.kafka.consumer.properties.request.timeout.ms=180000
## Kafka提供的序列化和反序列化类
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
## 消费端监听的topic不存在时，项目启动会报错(关掉)
#spring.kafka.listener.missing-topics-fatal=false
## 设置批量消费
## spring.kafka.listener.type=batch
## 批量消费每次最多消费多少条消息
## spring.kafka.consumer.max-poll-records=50
